《kafka权威指南》
1 初识kafka
	1.1发布与订阅消息系统
		数据（消息）的发送者（发布者）不会直接把消息发送给接收者，这是发布与订阅消息系统的一个特点。发布者以某种方式对消息进行分类，接收者（订阅者）订阅它们，以便接收特定类型的消息。发布与订阅系统一般会有一个broker ，也就是发布消息的中心点。
		1.1.1 如何开始
			发布与订阅消息系统的大部分应用场景都是从一个简单的消息队列或 个进程间通道开始的。
		1.1.2 独立的队列系统
			每个发布与订阅系统，这种方式比直接使用点对点的连接要好得多，但这里有太多重复的地方。你的公司因此要为数据队列维护多个系统。
	1.2 Kafka登场
		1.2.1 消息和批次
			Kafka 的数据单元被称为消息
			为了提高效率，消息被分批次写入 Kafka 批次就是 组消息
		1.2.2 模式
			根据应用程序的需求，消息模式(schema)有许可用的选项。json、xml
		1.2.3 主题和分区
			Kaflca 的悄息通过主题进行分类。
			主题就好比数据库的表，或者文件系统里的文件夹。主题可以被分为若干个分区，一个分区就是一个提交日志。要注意，由于一个主题一般包含几个分区，因此无法在整个主题范围内保证消息的顺序。
		1.2.4 生产者和消费者
			生产者创建消息。在其他发布与订阅系统中，生产者可能被称为发布者或写入者
			消费者读取消息。在其他发布与订阅系统中，消费者可能被称为订阅者或读者
			偏移量：消费者通过检查消息的偏移盘来区分已经读取过的消息。 偏移量是另 种元数据，它是个不断递增的整数值，在创建消息时，Kafka会把它添加到消息里。在给定的分区里，每个悄息的偏移量都是唯一的。消费者把每个分区最后读取的悄息偏移量保存在 Zookeeper或Kafka上
			消费者群组：消费者是消费者群组的一部分，也就是说，会有一个或多个消费者共同读取一个主题
			所有权关系：消费者与分区之间的映射通常被称为悄费者对分区的所有权关系
		1.2.5 broker和集群
			一个独立的Kafka服务器被称为broker。broker接收来自生产者的消息，为消息设置偏移量，并提交消息到磁盘保存。
			broker 是集群的组成部分。每个集群都有 broker 同时充当了集群控制器的角色（自动从集群的活跃成员中选举出来），该broker 被称为分区的首领。一个分区可以分配给多个 broke ，这个时候会发生分区复制。这种复制机制为分区提供了消息冗余。
			保留消息（在一定期限内）是 Kafka 个重要特性，要么保留一定时间，要么保留一定字节。主题可以配置自己的保留策略。
		1.2.6 多集群
			数据类型分离
			安全需求隔离
			多数据中心（灾难恢复）
	1.3 为什么选择Kafka
		1.3.1 多个生产者
			Kafka 可以无缝地支持多个生产者
		1.3.2 多个消费者
			Kafka 也支持多个消费者从一个单独的消息流上读取数据
		1.3.3 基于磁盘的数据存储
		1.3.4 伸缩性
		1.3.5 高性能
			上面提到的所有特性，让 Kafka 成为了 个高性能的发布与订阅消息系统。
		1.4 数据生态系统
			活动跟踪
			传递消息
			度量指标和日志记录
			提交日志
			流处理
		1.5kafka的起源
		1.6开始Kafka之旅
2 安装kafka
3 kafka生产者——向kafka写入数据
	3.1 生产者概览
		创建ProducerRecord对象->序列化器->分区器->Kafka Broker->如果成功返回元数据
	3.2 创建Kafka生产者
		Kafka 生产者有3个必选的属性
			bootstrap.servers
				指定broker的地址清单，建议提供至少2个，一旦其中一个宕机生产者依然能够连接到集群上
			key.serializer
				broker 希望接收到的消息的键和值都是字节数组
			value.serializer
				与key一样
		发送消息主要有以下3种方式
			发送并忘记(fire-and-forget)
				我们把消息发送给服务器，但井不关心它是否正常到达
			同步发送
				使用 send()方怯发送消息，返回一个Future对象，使用get()进行等待
			异步发送
				使用send()方法发送，服务器在返回响应时调用函数
	3.3 发送消息到Kafka
	3.4 生产者的配置
		1. acks
			指定必须要有多少个分区副本收到消息
		2. buffer.memory
			内存缓冲区大小
		3. compression.type
			默认发送不压缩
		4. retries
			可以重发消息的次数
		5. batch.size
			一个批次可以使用内存的大小
		6. linger.ms
			填满批次等待时间
		7. client.id
			生产者标识
		8. max.in.flight.requests.per.connection
			该参数指定了生产者在收到服务器晌应之前可以发送多少个消息
		9. timeout.ms、request.timeout.ms、metadata.fetch.timeout.ms
			同步broker响应事件、等待响应时间、获取元数据时间
		10. max.block.ms
			获取元数据的阻塞时间
		11. max.request.size
			生产者发送最大大小
		12. receive.buffer.bytes和send.buffer.bytes
			TCP接收和发送	数据包的缓冲区大小
		顺序消费
			Kafka 可以保证同一个分区里的消息是有序的
	3.5 序列化器
		3.5.1 自定义序列化器
		3.5.2 使用 Avro序列化
		3.5.3 Kafka 里使用 Avro
4 kafka消费者——从kafka读取数据
	4.1 KafkaConsumer概念
		4.1.1 消费者和消费者群组
			Kafka 消费者从属于消费者群组。一个群组里的消费者订阅的是同一个主题，每个消费接收主题一部分分区的消息。(一般一个消费者群里面的消费者平均分配分区)
		4.1.2 消费者群组和分区再均衡
			在主题发生变化时。比如管理员添加了新的分区，会发生分区重分配。这样的行为被称为再均衡。
			消费者通过向被指派为群组协调器的 broker （不同的群组可以有不同的协调器）发送心跳
	4.2 创建Kafka 消费者
	4.3 订阅主题
	4.4 轮询
		轮询不只是获取数据那么简单。在第一次调用新消费者的poll()方法时，它会负责查找GroupCoordinator然后加入群组，接受分配的分区。如果发生了再均衡，整个过程也是在轮询期间进行。当然，心跳也是从轮询里发送出去的。所以，我们要确保在轮询期间所做的任何处理工作都应该尽快完成。
	4.5 消费者的配置
	4.6 提交和偏移量
		我们把更新分区当前位置的操作叫作提交
		4.6.1 自动提交
		4.6.2 提交当前偏移量
		4.6.3 异步提交
		4.6.4 同步和异步组合提交
		4.6.5 提交特定的偏移量
	4.7 再均衡监昕器
	4.8 从特定偏移量处开始处理记录
	4.9 如何退出
	4.10 反序列化器
		1. 自定义反序列化器
		2. 在消费者里进行 Avro 反序列化
5 深入kafka
	5.1 集群成员关系
		Kafka 使用 Zookeeper 来维护集群成员的信息。在 broker 启动的时候，它通过创建临时节点把自己的 ID 注册到 Zookeeper。Kafka组件订阅 Zookeeper的／brokers/ids 路径(broker在Zookeeper 上的注册路径），当有 broker 加入集群或退出集群时，这些组件就可以获得通知。
	5.2 控制器
		控制器其实就是 broker ，只不过它除了具有一般 broker 的功能之外，还负责分区首领的选举。集群里第一个启动的 broker 通过Zookeper里创建一个临时节点／controller让自己成为控制器。
		简而言之， Kafka 使用 Zookeeper 的临时节点来选举控制器， 并在节点加入集群或退出集群时通知控制器。控制器负责在节点加入或离开集群时进行分区首领选举。控制器使用epoch 来避免“脑裂” 。“脑裂”是指两个节点同时认为自己是当前的控制器。
	5.3 复制
		Kafka使用主题来组织数据，每个主题被分为若干个分区，每个分区有多个副本
		副本有两种类型
			首领副本
			跟随者副本
	5.4 处理请求
		broker 的大部分工作是处理客户端、分区副本和控制器发送给分区首领的请求。 Kafka提供了一个二进制协议（基于TCP）
		broker 会在它所监听的每一个端口上运行一个Acceptor线程，这个钱程会创建一个连接，并把它交给Processor线程(网络线程)去处理。网络线程负责从客户端获取请求悄息，把它们放进请求队列，然后从晌应队列取响应消息
		5.4.1 生产请求
			在 Linux 系统上，消息会被写到文件系统缓存里，并不保证它们何时会被刷新到磁盘上。在消息被写入分区的首领之后，broker开始检 acks 配置参数，是立即返回还是同步给其它broker再返回
		5.4.2 获取请求
			Kafka 使用零复制技术向客户端发送消息一一也就是说， Kafka 直接把消息从文件（或者更确切地说是 Li ux 文件系统缓存）里发送到网络通道
		5.4.3 其他请求
			元数据请求
	5.5 物理存储
		Kafka 的基本存储单元是分区。分区无住在多个broker间进行再细分
		5.5.1 分区分配
			在创建主题时， Kafka 首先会决定如何在 broker 间分配分区。
		5.5.2 文件管理
		5.5.3 文件格式
		5.5.4 索引
			Kafka为每个分区维护了一个索引。
		5.5.5 清理
			时间/空间
		5.5.6 清理的工作原理
			每个日志片段可以分为以下两个部分。
				干净的部分：这些消息之前被清理过，每个键只有 个对应的值，这个值是上 次清理时保留下来的。
				污浊的部分：这些消息是在上 次清理之后写入的。
			每个 broker会启动一个清理管理器线程和多个清理线程，它们负责执行清理任务。这些线程会选择污浊率（污浊消息占分区总大小的比例）较高的分区进行清理。
			从最旧的消息开始，把它们的内容与map 里的内容进行比对。它会检查消息的键是否存在于 map 中，如果不存在，那么说明消息的值是最新的，就把消息复制到替换片段上 如果键已存在，消息会被忽略，
		5.5.7 被删除的事件
			为了彻底把一个键从系统里删除，应用程序必须发送一个包含该键且值为 null 的消息
		5.5.8 何时会清理主题
6 可靠的数据传递
	6.1 可靠性保证
		它是指确保系统在各种不同的环境下能够发生一致的行为。
	6.2 复制
		Kafka 的复制机制和分区的多副本架构是 Kafka 可靠性保证的核心。把 肖息写入多个副本可以使 Kafka 在发生崩愤时仍能保证消息的持久性。
	6.3 broker配置
		6.3.1 复制系数
			默认复制系数就是3，即被3个broker复制
		6.3.2 不完全的首领选举
			如果把 unclean.leade .election.enable 设为true ，就是允许不同步的副本成为首领
		6.3.3 最少同步副本
			如果要确保已提交的数据被写入不止一个副本，就需要把最少同步副本数量设置为大一点的值
	6.4 在可靠的系统里使用生产者
		6.4.1 发送确认
			acks=0(网络成功即为成功，网卡故障、分区离线则丢失数据)
			acks=1(写入缓存视作成功)
			ack s=all(所有副本都同步认为成功)
		6.4.2 配置生产者的重试参数
		6.4.3 额外的错误处理
	6.5 在可靠的系统里使用消费者
		6.5.1 消费者的可靠性配置
			group.id:如果有多个消费者在同一组订阅同一主题那么获得的信息则各位一部分
			auto.offset.reset：当发生偏移量异常时earlist(从头开始读，丢失情况少但性能低)latest(从尾读，性能高可能会丢数据)
			enable.auto.commit:自动提交可能会有重复消息
			auto.commit.interval.ms上一个参数的间隔时间默认5秒
		6.5.2 显式提交偏移量
	6.6 验证系统可靠性
7 构建数据管道
	7.1 构建数据管道时需要考虑的问题
		7.1.1 及时性
			Kafka 在这里扮演了一个大型缓冲区的角色
		7.1.2 可靠性
			至少一次传递
		7.1.3 高吞吐量和动态吞吐量
		7.1.4 数据格式
		7.1.5 转换
		7.1.6 安全性
		7.1.7 故障处理能力
		7.1.8 糯合性和灵活性
	7.2 如何在Connect API 和客户端API 之间作出选择
	7 .3 Kafka Connect
		Connect是Kafka一部分，它为在 Kafka 和外部数据存储系统之间移动数据提供了可靠且可伸缩的方式。它为连接器插件提供了一组API和一个运行时-Connect 负责运行这些插件
	7.4 Connect之外的选择
8 跨集群数据镜像
	把集群间的数据复制叫作镜像
	
9 管理kafka
10 监控kafka
11 流式处理